// utils/generateArticle.js - MODIFICATIONS COMPL√àTES
import axios from 'axios';
import { OPENROUTER_AI_API, OPENROUTER_AI_KEY } from '../config/ia.js';
import { checkAiGenerationsLimit } from '../services/aiModel.service.js';

function cleanArticleContent(content) {
  if (!content) return '';

  return content
    // Normaliser les sauts de ligne
    .replace(/\r\n/g, '\n')
    .replace(/\r/g, '\n')

    // Supprimer les backslashes isol√©s AVANT guillemets
    .replace(/\\(?=["'])/g, '')

    // Nettoyer les espaces excessifs
    .replace(/[ \t]+/g, ' ')
    .replace(/\n{3,}/g, '\n\n')
    .trim();
}


/**
 * G√©n√®re des articles avec gestion des mod√®les IA selon l'abonnement
 */
export async function generateArticles(params) {
  const {
    numArticles,
    topic,
    language,
    siteName,
    userId,
    aiModel // NOUVEAU: Mod√®le IA sp√©cifique (optionnel)
  } = params;

  console.log('üìù D√©but g√©n√©ration articles:', {
    numArticles,
    topic,
    language,
    userId,
    model: aiModel ? `${aiModel.provider}/${aiModel.modelId}` : 'd√©faut'
  });

  const articles = [];

  // D√©terminer le mod√®le √† utiliser
  const modelToUse = await determineArticleAiModel(aiModel, userId);
  
  console.log(`üéØ Utilisation du mod√®le: ${modelToUse.name} (${modelToUse.modelId})`);

  try {
  // V√©rifier les limites avant de g√©n√©rer (s√©curit√© suppl√©mentaire)
  if (userId) {
    const limitCheck = await checkAiGenerationsLimit(userId);
    
    if (!limitCheck.allowed) {
      throw new Error(`Limite de g√©n√©rations IA atteinte. Restant: ${limitCheck.remaining}/${limitCheck.limit}`);
    }
  }

    // Prompt optimis√© pour un format coh√©rent
    const promptBase = (theme, lang, articleNum) => `
  Cr√©e un article de blog ${lang === 'fr_FR' ? 'en_US fran√ßais' : 'in English'} sur le th√®me : "${theme}".

  EXIGENCES STRICTES:
  - TITRE UNIQUEMENT sur la premi√®re ligne (sans #, sans **, sans formatage markdown)
  - Contenu √† partir de la deuxi√®me ligne
  - Structure: introduction, 2-3 paragraphes de d√©veloppement, conclusion
  - Style professionnel et engageant
  - Longueur: 300-500 mots
  - Th√®me sp√©cifique: ${theme} ${articleNum > 1 ? `(variation ${articleNum})` : ''}

  FORMAT EXACT:
  [Titre simple et accrocheur]
  [Ligne vide]
  [Contenu de l'article avec des paragraphes s√©par√©s par des lignes vides]
  `;

    for (let i = 0; i < numArticles; i++) {
      const prompt = promptBase(topic, language, i + 1);

      try {
        console.log(`üìù G√©n√©ration de l'article ${i + 1}/${numArticles} avec ${modelToUse.name}...`);
        
        const response = await axios.post(
          OPENROUTER_AI_API,
          {
            model: `${modelToUse.modelId}`, // NOUVEAU: Mod√®le dynamique
            messages: [
              { 
                role: 'system', 
                content: getSystemPrompt(language, modelToUse) // NOUVEAU: Prompt syst√®me adapt√©
              },
              { role: 'user', content: prompt },
            ],
            max_tokens: getMaxTokensForModel(modelToUse), // NOUVEAU: Tokens adapt√©s
            temperature: getTemperatureForModel(modelToUse), // NOUVEAU: Temp√©rature adapt√©e
          },
          {
            headers: {
              'Authorization': `Bearer ${OPENROUTER_AI_KEY}`,
              'Content-Type': 'application/json',
            },
            timeout: getTimeoutForModel(modelToUse), // NOUVEAU: Timeout adapt√©
          }
        );

        let content = response.data.choices[0].message.content;
        
        console.log(`üìã R√©ponse brute (d√©but):`, content.substring(0, 150) + '...');

        content = cleanArticleContent(content);

        // Nettoyage et extraction am√©lior√©s
        const { title, body } = extractTitleAndBody(content, topic, i + 1, language);
        
        console.log(`‚úÖ Article ${i + 1} - Titre: "${title}"`);
        console.log(`üìù Extrait: "${body.substring(0, 80)}..."`);

        articles.push({ 
          title: title, 
          content: body,
          excerpt: generateExcerpt(body, language),
          status: 'publish',
          comment_status: 'open',
          aiModel: modelToUse.name // NOUVEAU: Tracking du mod√®le utilis√©
        });

        // Pause progressive adapt√©e au mod√®le
        const delay = getDelayForModel(modelToUse, i);
        if (i < numArticles - 1) {
          console.log(`‚è≥ Attente de ${delay}ms avant le prochain article...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }

      } catch (err) {
        console.error(`‚ùå Erreur g√©n√©ration article ${i + 1} avec ${modelToUse.name}:`, err.response?.data || err.message);
        
        // Essayer avec un mod√®le de fallback si possible
        if (i === 0 && !modelToUse.isDefault) {
          console.log('üîÑ Tentative avec mod√®le de fallback...');
          try {
            const fallbackModel = getDefaultAiModel();
            const fallbackArticle = await generateSingleArticleWithModel(fallbackModel, prompt, topic, i + 1, language);
            articles.push(fallbackArticle);
            continue;
          } catch (fallbackError) {
            console.error('‚ùå √âchec √©galement avec le mod√®le de fallback');
          }
        }
        
        // Article de secours am√©lior√©
        const fallbackArticle = createFallbackArticle(topic, i + 1, language, modelToUse);
        articles.push(fallbackArticle);
        
        // Pause plus longue en_US cas d'erreur
        await new Promise(resolve => setTimeout(resolve, 3000));
      }
    }

    console.log(`üéâ ${articles.length}/${numArticles} articles g√©n√©r√©s avec ${modelToUse.name}`);
    // Enregistrer l'usage pour les articles g√©n√©r√©s
    if (userId && articles.length > 0) {
      try {
        const { recordAiGenerationUsage } = await import('../services/aiModel.service.js');
        await recordAiGenerationUsage(userId, {
          count: articles.length * (modelToUse.costPerGeneration || 1),
          generationType: 'article',
          aiModel: modelToUse.name,
          articlesGenerated: articles.length,
          topic: topic,
          tokensUsed: estimateTokensForArticles(articles)
        });
      } catch (trackingError) {
        console.warn('‚ö†Ô∏è Erreur tracking usage articles:', trackingError.message);
      }
    }
    
    return articles;

  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration articles:', error);
    throw error;
  }
}

function estimateTokensForArticles(articles) {
  return articles.reduce((total, article) => {
    return total + (article.content?.length || 0) / 4;
  }, 0);
}

/**
 * D√©termine le mod√®le IA √† utiliser pour les articles
 */
async function determineArticleAiModel(providedAiModel, userId) {
  // Si un mod√®le est fourni explicitement, l'utiliser
  if (providedAiModel) {
    return providedAiModel;
  }

  // Si un userId est fourni, essayer de r√©cup√©rer le mod√®le selon l'abonnement
  if (userId) {
    try {
      // NOUVEAU: Import dynamique pour √©viter les d√©pendances circulaires
      const { getAiModelForUser } = await import('../services/aiModelService.js');
      const userAiModel = await getAiModelForUser(userId, 'article');
      console.log(`üéØ Mod√®le utilisateur s√©lectionn√©: ${userAiModel.name}`);
      return userAiModel;
    } catch (error) {
      console.warn('‚ö†Ô∏è Erreur r√©cup√©ration mod√®le utilisateur:', error.message);
    }
  }

  // Fallback vers un mod√®le par d√©faut
  return getDefaultAiModel();
}

/**
 * Retourne le mod√®le IA par d√©faut
 */
function getDefaultAiModel() {
  return {
    id: 0,
    name: 'OpenAI GPT-3.5 Turbo',
    provider: 'openai',
    modelId: 'gpt-3.5-turbo',
    isDefault: true
  };
}

/**
 * G√©n√®re un seul article avec un mod√®le sp√©cifique (pour les retry)
 */
async function generateSingleArticleWithModel(aiModel, prompt, topic, index, language) {
  const response = await axios.post(
    OPENROUTER_AI_API,
    {
      model: `${aiModel.provider}/${aiModel.modelId}`,
      messages: [
        { 
          role: 'system', 
          content: getSystemPrompt(language, aiModel)
        },
        { role: 'user', content: prompt },
      ],
      max_tokens: getMaxTokensForModel(aiModel),
      temperature: getTemperatureForModel(aiModel),
    },
    {
      headers: {
        'Authorization': `Bearer ${OPENROUTER_AI_KEY}`,
        'Content-Type': 'application/json',
      },
      timeout: getTimeoutForModel(aiModel),
    }
  );

  let content = response.data.choices[0].message.content;
  content = cleanArticleContent(content);
  
  const { title, body } = extractTitleAndBody(content, topic, index, language);
  
  return {
    title: title, 
    content: body,
    excerpt: generateExcerpt(body, language),
    status: 'publish',
    comment_status: 'open',
    aiModel: aiModel.name
  };
}

/**
 * Retourne le prompt syst√®me adapt√© au mod√®le
 */
function getSystemPrompt(language, aiModel) {
  const basePrompt = `Tu es un r√©dacteur professionnel sp√©cialis√© dans la cr√©ation de contenu pour blogs. 
  Retourne TOUJOURS le titre sur la premi√®re ligne (sans aucun formatage markdown).
  Le contenu doit commencer √† partir de la troisi√®me ligne.
  Utilise un style clair, professionnel et engageant.`;
  
  // Adaptations selon le mod√®le
  if (aiModel.modelId.includes('gpt-4')) {
    return `${basePrompt} Sois particuli√®rement cr√©atif et approfondi dans ton analyse.`;
  } else if (aiModel.modelId.includes('claude-3')) {
    return `${basePrompt} Fais preuve de r√©flexion approfondie et de structure logique.`;
  }
  
  return basePrompt;
}

/**
 * Retourne le nombre max de tokens selon le mod√®le
 */
function getMaxTokensForModel(aiModel) {
  if (aiModel.modelId.includes('gpt-4')) {
    return 2000; // Plus de tokens pour GPT-4
  } else if (aiModel.modelId.includes('claude-3')) {
    return 2500; // Claude peut g√©rer plus de tokens
  }
  return 1500; // D√©faut pour GPT-3.5
}

/**
 * Retourne la temp√©rature selon le mod√®le
 */
function getTemperatureForModel(aiModel) {
  if (aiModel.modelId.includes('gpt-4')) {
    return 0.7; // Un peu plus cr√©atif pour GPT-4
  } else if (aiModel.modelId.includes('claude-3')) {
    return 0.8; // Claude peut √™tre plus cr√©atif
  }
  return 0.8; // D√©faut
}

/**
 * Retourne le timeout selon le mod√®le
 */
function getTimeoutForModel(aiModel) {
  if (aiModel.modelId.includes('gpt-4') || aiModel.modelId.includes('claude-3')) {
    return 60000; // Timeout plus long pour les mod√®les plus lents
  }
  return 45000; // D√©faut
}

/**
 * Retourne le d√©lai entre les requ√™tes selon le mod√®le
 */
function getDelayForModel(aiModel, articleIndex) {
  let baseDelay;
  
  if (aiModel.modelId.includes('gpt-4') || aiModel.modelId.includes('claude-3')) {
    baseDelay = 2000; // Mod√®les plus lents, besoin de plus de temps
  } else {
    baseDelay = 1000; // Mod√®les rapides
  }
  
  return baseDelay + (articleIndex * 500); // Progressive delay
}

// FONCTIONS EXISTANTES (conserv√©es avec am√©liorations)

function extractTitleAndBody(content, topic, index, language) {
  const lines = content.split('\n')
    .map(line => line.trim())
    .filter(line => line.length > 0);

  let title, body;

  if (lines.length === 0) {
    title = getDefaultTitle(topic, index, language);
    body = getDefaultContent(topic, language);
  } else if (lines.length === 1) {
    title = lines[0].substring(0, 200);
    body = getDefaultContent(topic, language);
  } else {
    title = lines[0].substring(0, 200);
    const bodyStartIndex = lines[1].length === 0 ? 2 : 1;
    body = lines.slice(bodyStartIndex).join('\n\n').trim();
    
    if (!body || body.length < 50) {
      body = getDefaultContent(topic, language);
    }
  }

  title = cleanArticleContent(title);
  body = cleanArticleContent(body);

  return { title, body };
}

function generateExcerpt(content, language) {
  const sentences = content.split(/[.!?]+/);
  const firstSentence = sentences[0]?.trim() || content.substring(0, 150);
  
  return firstSentence.length > 150 
    ? firstSentence.substring(0, 147) + '...'
    : firstSentence;
}

// Articles de secours par langue avec information du mod√®le
function createFallbackArticle(topic, index, language, aiModel) {
  const titles = {
    fr_FR: [
      `Les avantages de ${topic}`,
      `Guide complet sur ${topic}`,
      `${topic} : Tout ce que vous devez savoir`,
      `Comment ma√Ætriser ${topic}`,
      `Les tendances actuelles de ${topic}`
    ],
    en_US: [
      `The Benefits of ${topic}`,
      `Complete Guide to ${topic}`,
      `${topic}: Everything You Need to Know`,
      `How to Master ${topic}`,
      `Current Trends in ${topic}`
    ]
  };

  const contents = {
    fr_FR: `Cet article explore en_US d√©tail le th√®me de ${topic}. Nous aborderons les aspects fondamentaux ainsi que les applications pratiques. Vous d√©couvrirez comment ${topic} peut transformer votre approche et quels sont les meilleures pratiques √† adopter. Que vous soyez d√©butant ou expert, ce contenu vous apportera des insights pr√©cieux.`,
    en_US: `This article provides an in-depth exploration of ${topic}. We will cover the fundamental aspects as well as practical applications. You will discover how ${topic} can transform your approach and what are the best practices to adopt. Whether you are a beginner or an expert, this content will bring you valuable insights.`
  };

  const lang = language === 'fr_FR' ? 'fr_FR' : 'en_US';
  const titleIndex = Math.min(index - 1, titles[lang].length - 1);
  
  return {
    title: titles[lang][titleIndex] || getDefaultTitle(topic, index, language),
    content: contents[lang],
    excerpt: generateExcerpt(contents[lang], language),
    status: 'publish',
    comment_status: 'open',
    aiModel: aiModel ? `Fallback (${aiModel.name})` : 'Fallback System'
  };
}

function getDefaultTitle(topic, index, language) {
  return language === 'fr_FR' 
    ? `Article ${index} sur ${topic}`
    : `Article ${index} about ${topic}`;
}

function getDefaultContent(topic, language) {
  return language === 'fr_FR'
    ? `Contenu g√©n√©r√© par IA.`
    : `Content generated by AI.`;
}